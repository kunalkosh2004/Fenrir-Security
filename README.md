# Fenrir Security AI/ML Internship - Technical Task

## ğŸ“Œ Overview

This project demonstrates an **end-to-end CLI-based intelligent agent** fine-tuned on public **command-line Q&A** datasets. It is designed to accept natural-language instructions from the user, generate actionable plans using a fine-tuned small language model, and simulate execution.

## ğŸ“‚ Project Structure

```
Fenrir-Security/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cli_qa_dataset.json        # â‰¥150 validated Q&A pairs (generated via generate_dataset.py)
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ trace.jsonl                # Logs generated by agent runs
â”œâ”€â”€ eval/
â”‚   â””â”€â”€ eval_static.py
|   â””â”€â”€ eval_dynamic.py
â”œâ”€â”€ agent.py                       # CLI agent script
â”œâ”€â”€ generate_dataset.py            # Script to collect & preprocess Q&A dataset
â”œâ”€â”€ finetune_model.py              # Script to fine-tune the model with LoRA/QLoRA
â”œâ”€â”€ eval_static.md                 # Static evaluation results
â”œâ”€â”€ eval_dynamic.md                # Dynamic evaluation with score tables
â”œâ”€â”€ report.md                      # Final one-page summary report
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ README.md                      # This file
â””â”€â”€ demo.mp4                       # â‰¤5 min video walkthrough
```

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone and Setup

```bash
git clone git@github.com:kunalkosh2004/Fenrir-Security.git
cd Fenrir-Security
```

### 2ï¸âƒ£ Create Virtual Environment & Install Dependencies

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

Example `requirements.txt`:

```
transformers
peft
datasets
accelerate
evaluate
torch
tqdm
rouge_score
```

## ğŸ“¦ Dataset Generation

Generate â‰¥150 public Q&A pairs on command-line topics:

```bash
python generate_dataset.py
```

- Output: `data/commandline_qa.json`
- Topics covered: Git, Bash, tar/gzip, grep, Python venv, etc.

## ğŸ¯ Fine-Tuning the Model

We use **LoRA** for efficient parameter-efficient fine-tuning on free-tier GPUs like Google Colab (T4).

```bash
python finetune_model.py
```

- Model used: Example `TinyLlama-1.1B` or `Phi-2`
- Adapter output: `models/adapter/`
- Configuration:
  - Epochs: 1
  - LoRA parameters adjustable in `finetune_model.py`

## â–¶ï¸ Running the CLI Agent

Once the adapter is ready:

```bash
python agent.py "Create a new Git branch and switch to it"
```

- **Functionality**:
  - Generates step-by-step execution plan.
  - Echoes shell command (dry-run mode).
  - Logs entire session to `logs/trace.jsonl`.

Example:

```
$ python agent.py "List all files including hidden ones"
Generated Plan:
1. Use the ls command with -a option.
2. Command to run: ls -a
[Dry-run] echo ls -a
```

## ğŸ“Š Evaluation

1. **Static Evaluation**: `eval_static.md`
   - Manual comparison of model generations before & after fine-tuning.
   - Metrics used: **BLEU**, **ROUGE-L**.
2. **Dynamic Evaluation**: `eval_dynamic.md`
   - Real CLI agent runs with scoring: 0 (poor) to 2 (excellent).

## ğŸ“ Reporting

See `report.md` for:

- Data sources
- Training configuration
- Time taken, costs (Colab hours)
- Metric results
- Two proposed improvements for future versions
