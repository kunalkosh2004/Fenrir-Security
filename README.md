# Fenrir Security AI/ML Internship - Technical Task

## 📌 Overview

This project demonstrates an **end-to-end CLI-based intelligent agent** fine-tuned on public **command-line Q&A** datasets. It is designed to accept natural-language instructions from the user, generate actionable plans using a fine-tuned small language model, and simulate execution.

## 📂 Project Structure

```
Fenrir-Security/
├── data/
│   └── cli_qa_dataset.json        # ≥150 validated Q&A pairs (generated via generate_dataset.py)
├── logs/
│   └── trace.jsonl                # Logs generated by agent runs
├── eval/
│   └── eval_static.py
|   └── eval_dynamic.py
├── agent.py                       # CLI agent script
├── generate_dataset.py            # Script to collect & preprocess Q&A dataset
├── finetune_model.py              # Script to fine-tune the model with LoRA/QLoRA
├── eval_static.md                 # Static evaluation results
├── eval_dynamic.md                # Dynamic evaluation with score tables
├── report.md                      # Final one-page summary report
├── requirements.txt               # Python dependencies
├── README.md                      # This file
└── demo.mp4                       # ≤5 min video walkthrough
```

## ⚙️ Setup Instructions

### 1️⃣ Clone and Setup

```bash
git clone git@github.com:kunalkosh2004/Fenrir-Security.git
cd Fenrir-Security
```

### 2️⃣ Create Virtual Environment & Install Dependencies

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

Example `requirements.txt`:

```
transformers
peft
datasets
accelerate
evaluate
torch
tqdm
rouge_score
```

## 📦 Dataset Generation

Generate ≥150 public Q&A pairs on command-line topics:

```bash
python generate_dataset.py
```

- Output: `data/commandline_qa.json`
- Topics covered: Git, Bash, tar/gzip, grep, Python venv, etc.

## 🎯 Fine-Tuning the Model

We use **LoRA** for efficient parameter-efficient fine-tuning on free-tier GPUs like Google Colab (T4).

```bash
python finetune_model.py
```

- Model used: Example `TinyLlama-1.1B` or `Phi-2`
- Adapter output: `models/adapter/`
- Configuration:
  - Epochs: 1
  - LoRA parameters adjustable in `finetune_model.py`

## ▶️ Running the CLI Agent

Once the adapter is ready:

```bash
python agent.py "Create a new Git branch and switch to it"
```

- **Functionality**:
  - Generates step-by-step execution plan.
  - Echoes shell command (dry-run mode).
  - Logs entire session to `logs/trace.jsonl`.

Example:

```
$ python agent.py "List all files including hidden ones"
Generated Plan:
1. Use the ls command with -a option.
2. Command to run: ls -a
[Dry-run] echo ls -a
```

## 📊 Evaluation

1. **Static Evaluation**: `eval_static.md`
   - Manual comparison of model generations before & after fine-tuning.
   - Metrics used: **BLEU**, **ROUGE-L**.
2. **Dynamic Evaluation**: `eval_dynamic.md`
   - Real CLI agent runs with scoring: 0 (poor) to 2 (excellent).

## 📝 Reporting

See `report.md` for:

- Data sources
- Training configuration
- Time taken, costs (Colab hours)
- Metric results
- Two proposed improvements for future versions
